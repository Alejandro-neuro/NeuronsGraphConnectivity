{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import models\n",
    "import loss_func\n",
    "import train\n",
    "import loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n",
      "optimize:\n",
      "  optimizer: Adam\n",
      "  lr: 0.001\n",
      "train:\n",
      "  epochs: 100\n",
      "  batch_size: 32\n",
      "dataset:\n",
      "  path: MNIST\n",
      "  test_size: 0.2\n",
      "  train_size: 0.8\n",
      "  val_size: 0.2\n",
      "  num_workers: 2\n",
      "--ip: 127.0.0.1\n",
      "--stdin: 9008\n",
      "--control: 9006\n",
      "--hb: 9005\n",
      "--Session:\n",
      "  signature_scheme: hmac-sha256\n",
      "  key: b\"1a3cc150-9f71-4e45-9ed5-a321d1cf0f3c\"\n",
      "--shell: 9007\n",
      "--transport: tcp\n",
      "--iopub: 9009\n",
      "--f: c:\\Users\\aleja\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-23880C8Yf42Y2bH94.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load(\"config.yaml\")\n",
    "cmd_cfg = OmegaConf.from_cli()\n",
    "cfg = OmegaConf.merge(cfg, cmd_cfg)\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.dataset.test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 998) (10,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [998, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m timeseries \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(\u001b[39m10\u001b[39m, \u001b[39m1000\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m train_loader, val_loader, test_loader \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39;49mgenerateLoaders(timeseries, \u001b[39m'\u001b[39;49m\u001b[39mpearson\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\Documents\\TUDelft\\Repository\\NeuronsGraphConnectivity\\loader.py:128\u001b[0m, in \u001b[0;36mgenerateLoaders\u001b[1;34m(timeseries, type)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerateLoaders\u001b[39m( timeseries, \u001b[39mtype\u001b[39m):\n\u001b[1;32m--> 128\u001b[0m     dataset \u001b[39m=\u001b[39m timeSeries2Dataset(timeseries)\n\u001b[0;32m    130\u001b[0m     G \u001b[39m=\u001b[39m generateGraph(dataset,\u001b[39mtype\u001b[39m)\n\u001b[0;32m    132\u001b[0m     train_loader,val_loader,test_loader \u001b[39m=\u001b[39m create_partitions(G,dataset)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\Documents\\TUDelft\\Repository\\NeuronsGraphConnectivity\\loader.py:53\u001b[0m, in \u001b[0;36mtimeSeries2Dataset\u001b[1;34m(timeseries)\u001b[0m\n\u001b[0;32m     49\u001b[0m cfg \u001b[39m=\u001b[39m OmegaConf\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mconfig.yaml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m test_size \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mtest_size\n\u001b[1;32m---> 53\u001b[0m X_train, X_test, y_train, y_test  \u001b[39m=\u001b[39m train_test_split(data\u001b[39m.\u001b[39;49mT, labels\u001b[39m.\u001b[39;49mT, test_size\u001b[39m=\u001b[39;49mtest_size, random_state\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     55\u001b[0m \u001b[39mprint\u001b[39m(X_train\u001b[39m.\u001b[39mshape, X_test\u001b[39m.\u001b[39mshape, y_train\u001b[39m.\u001b[39mshape, y_test\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     57\u001b[0m val_size \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mval_size \u001b[39m/\u001b[39m cfg\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mtrain_size\n",
      "File \u001b[1;32mc:\\Users\\aleja\\Documents\\TUDelft\\Repository\\NeuronsGraphConnectivity\\.conda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aleja\\Documents\\TUDelft\\Repository\\NeuronsGraphConnectivity\\.conda\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\aleja\\Documents\\TUDelft\\Repository\\NeuronsGraphConnectivity\\.conda\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [998, 10]"
     ]
    }
   ],
   "source": [
    "timeseries = np.random.rand(10, 1000)\n",
    "\n",
    "train_loader, val_loader, test_loader = loader.generateLoaders(timeseries, 'pearson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
